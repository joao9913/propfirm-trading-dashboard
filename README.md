# Overview
Python analytics application designed to process, validate and analyse CSV output files, generated by prop-firm trading simulations.
The project transforms raw simulation data into structured metrics and reports, with a strong emphasis on clean architecture, separation of concerns and maintainable design (also scalable in the future)
The application is intentionally built as portfolio-grade software project, showcasing pratical data processing, validation and analytical workflows commonly found in production systems. While the domain is trading, the focus is on software engineering principles.
This project is actively developed and shared publicly as part of my professional portfolio, with particular relevance towards data processing, analytics tooling and backend-oriented python development.

# Functionality
1. CSV Parsing & Validation
  - Loads simulation CSV files produced by the Metatrader5 platform (generated by the other MQL5 project)
  - Validates file structure and required columns before any analytics are performed
  - Fails fast with descriptive errors when invalid or malformed data is detected

2. Metrics Calculation Engine
  - Centralised MetricsCalculator component responsible for all analytics
  - Metrics are calculated per simulation phase (P1, P2, P3, Challenge and Funded)
  - Phase specific logic is isolated using internal dispaching and private methods
  - Designed to be easily extended as new metrics or simulation types are added (1 Step, Instant-Funding, etc)

3. Report Generation
  -  Generates structured reports from calculated metrics in an html/css report
  -  Supports aggregation and formatting suitable for analysis and presentation
  -  Separates logic from reporting, ensuring metrics are reusable

4. CLI-Oriented
  - cli.py - entry point responsible for orchestration and execution flow
  - csv_parser.py - handles csv loading and validation
  - metrics.py - containts the MetricsCalculator class and all phase-specific analytics logic
  - report.py - reserved for report generation and output formatting
  - data/ - sample csv files used for development and testing

# Design Philosophy
  - Single Responsibility - each module has one clear purpose: parsing, validation, analytics or orchestration
  - Explicit - clear function boundaries, explicit phase handling and descriptive errors
  - Scalability - new simulation types, new metrics or output formats can be added without refactoring excessively
  - Production - Validation first workflows, deterministic outputs and testable components
  - Domain-Agnostic - although aplied to trading, the architecture is focused on applying software development practices

# Intended Use
  - Demonstration of python software skills
  - Practical example of data validation and analytical pipelines
  - Foundation for more advanced reporting, visualization or automation tools

# Future Features/Roadmap
1. Database Integration
  - Store all metrics, reports and R&D data in a structured database using Django ORM
  - Enable persistent storage, querying and analytics across multiple simulation runs
2. Graphical User Interface (GUI)
  - Replace the CLI with a GUI for easier interaction and use
  - Will probably be implemented with frameworks like PyQt/Tkinter or web-based interfaces
3. Web Hosting & Containerization
  - Host the app on a web server and package it using Docker
  - Ensure portability, easy deployment and scalability
4. REST API with FastAPI
  - Expose the metrics calculations and report generation as REST endpoints
  - Users could upload csv files via an API call, request metrics for a specific simulation or retrieve strucutred results and reports in JSON
  - Integrating FastAPI prepares the project for web or GUI frontends later
